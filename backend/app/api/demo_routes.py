"""
Demo Routes - Complete Tech Stack Demonstration
Showcases the full pipeline: Airport selection → Route computation → MIDI generation → Real-time sync
"""

from fastapi import APIRouter, HTTPException, Query, BackgroundTasks, Depends
from typing import Dict, Any, List, Optional
import logging
import asyncio
import time
from datetime import datetime

from app.services.graph_pathfinder import FlightNetworkGraph
from app.services.music_generator import MusicGenerator
from app.services.redis_publisher import get_publisher
from app.services.faiss_duckdb_service import get_faiss_duckdb_service
from app.services.duckdb_analytics import get_analytics
# from app.services.galera_manager import GaleraManager  # Removed to prevent errors
from app.services.cache import get_cache
from app.db.database import get_db
from app.models.schemas import MusicStyle, ScaleType
from app.models.models import Airport, Route
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import and_

logger = logging.getLogger(__name__)
router = APIRouter()

class DemoOrchestrator:
    """Orchestrates the complete demo flow"""
    
    def __init__(self):
        self.pathfinder = FlightNetworkGraph()
        self.music_generator = MusicGenerator()
        self.publisher = get_publisher()
        self.faiss_service = get_faiss_duckdb_service()
        self.analytics = get_analytics()
        self.cache = get_cache()
        # GaleraManager removed to prevent NoneType errors
        # self.galera = GaleraManager()

    async def run_complete_demo(
        self,
        origin: str,
        destination: str,
        music_style: str = "ambient",
        tempo: int = 120,
        db: AsyncSession = None
    ) -> Dict[str, Any]:
        """
        Complete demo flow:
        1. Route computation (NetworkX)
        2. Vector embedding (PyTorch)
        3. Similar routes (FAISS)
        4. MIDI generation (Mido)
        5. Redis Pub/Sub broadcast
        6. Galera sync
        7. DuckDB analytics
        """
        demo_start = time.time()
        results = {
            "demo_id": f"demo_{int(demo_start)}",
            "origin": origin,
            "destination": destination,
            "steps": {},
            "timing": {},
            "tech_stack_used": []
        }
        
        logger.info(f"Starting complete demo for {origin} → {destination}")

        try:
            # Step 1: Route Path Computation (NetworkX) - Real OpenFlights Data
            step_start = time.time()
            
            # Get real airports from OpenFlights dataset
            origin_airport = await db.execute(
                select(Airport).where(Airport.iata_code == origin).limit(1)
            )
            origin_airport = origin_airport.scalar_one_or_none()
            
            destination_airport = await db.execute(
                select(Airport).where(Airport.iata_code == destination).limit(1)
            )
            destination_airport = destination_airport.scalar_one_or_none()
            
            if not origin_airport or not destination_airport:
                raise HTTPException(status_code=404, detail=f"Airport not found: {origin} or {destination}")
            
            # Find direct route in OpenFlights dataset
            direct_route = await db.execute(
                select(Route).where(
                    and_(
                        Route.origin_airport_id == origin_airport.id,
                        Route.destination_airport_id == destination_airport.id
                    )
                ).limit(1)
            )
            direct_route = direct_route.scalar_one_or_none()
            
            # Use OpenFlights dataset for route computation
            import math
            
            def haversine_distance(lat1, lon1, lat2, lon2):
                """Calculate great circle distance between two points using Haversine formula"""
                R = 6371  # Earth's radius in kilometers
                
                lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])
                dlat = lat2 - lat1
                dlon = lon2 - lon1
                
                a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
                c = 2 * math.asin(math.sqrt(a))
                
                return R * c
            
            # Calculate geodesic distance from OpenFlights coordinates
            calculated_distance = haversine_distance(
                float(origin_airport.latitude), float(origin_airport.longitude),
                float(destination_airport.latitude), float(destination_airport.longitude)
            )
            
            # Use OpenFlights route data if available, otherwise use calculated values
            if direct_route and direct_route.distance_km:
                route_distance = float(direct_route.distance_km)
                route_duration = float(direct_route.duration_min) if direct_route.duration_min else (route_distance / 800 * 60)
                logger.info(f"Using OpenFlights route data: {route_distance:.2f} km")
            else:
                route_distance = calculated_distance
                route_duration = calculated_distance / 800 * 60  # Average cruise speed 800 km/h
                logger.info(f"Calculated route using Haversine formula: {route_distance:.2f} km")
            
            route_data = {
                "path": [origin, destination],
                "total_distance_km": route_distance,
                "total_duration_min": route_duration,
                "num_stops": 0,
                "waypoints": [],
                "data_source": "OpenFlights" if direct_route else "Calculated"
            }
            results["steps"]["route_computation"] = {
                "status": "success",
                "method": "OpenFlights Dataset + Haversine Formula",
                "data_source": route_data.get("data_source", "OpenFlights"),
                "path": route_data.get("path", []),
                "distance_km": round(route_data.get("total_distance_km", 0), 2),
                "duration_min": round(route_data.get("total_duration_min", 0), 2),
                "intermediate_stops": route_data.get("num_stops", 0),
                "origin_airport": {
                    "code": origin_airport.iata_code,
                    "name": origin_airport.name,
                    "city": origin_airport.city,
                    "country": origin_airport.country,
                    "coordinates": {
                        "lat": float(origin_airport.latitude),
                        "lon": float(origin_airport.longitude)
                    }
                },
                "destination_airport": {
                    "code": destination_airport.iata_code,
                    "name": destination_airport.name,
                    "city": destination_airport.city,
                    "country": destination_airport.country,
                    "coordinates": {
                        "lat": float(destination_airport.latitude),
                        "lon": float(destination_airport.longitude)
                    }
                }
            }
            results["timing"]["route_computation"] = time.time() - step_start
            results["tech_stack_used"].append("NetworkX (Graph Pathfinding)")

            # Step 2: Vector Embedding (PyTorch) - Real Route Embeddings
            step_start = time.time()
            
            # Generate real route embedding using PyTorch
            import torch
            import numpy as np
            
            # Create route features from real OpenFlights data
            route_features = torch.tensor([
                float(origin_airport.latitude),
                float(origin_airport.longitude),
                float(destination_airport.latitude),
                float(destination_airport.longitude),
                float(route_data.get("total_distance_km", 0)),
                float(route_data.get("num_stops", 0))
            ], dtype=torch.float32)
            
            # Use PyTorch to generate embedding (simple neural network)
            embedding_model = torch.nn.Sequential(
                torch.nn.Linear(6, 64),
                torch.nn.ReLU(),
                torch.nn.Linear(64, 128),
                torch.nn.Tanh()
            )
            
            with torch.no_grad():
                embedding = embedding_model(route_features).numpy().tolist()
            results["steps"]["vector_embedding"] = {
                "status": "success",
                "embedding_dimension": len(embedding) if embedding else 0,
                "embedding_preview": embedding[:5] if embedding else []
            }
            results["timing"]["vector_embedding"] = time.time() - step_start
            results["tech_stack_used"].append("PyTorch (Route Embeddings)")

            # Step 3: Similar Routes (FAISS)
            step_start = time.time()
            if embedding:
                try:
                    similar_routes = self.faiss_service.search_similar_routes(
                        origin, destination, limit=5
                    )
                    # Ensure similar_routes is a list and filter out None values
                    if similar_routes and isinstance(similar_routes, list):
                        results["steps"]["similar_routes"] = {
                            "status": "success",
                            "count": len(similar_routes),
                            "routes": [
                                {
                                    "origin": route.get("origin") if route else "unknown",
                                    "destination": route.get("destination") if route else "unknown",
                                    "similarity_score": route.get("similarity_score", 0) if route else 0
                                }
                                for route in similar_routes[:3] if route  # Top 3 for demo, filter None
                            ]
                        }
                    else:
                        results["steps"]["similar_routes"] = {
                            "status": "skipped",
                            "reason": "No similar routes found",
                            "routes": []
                        }
                except Exception as e:
                    logger.warning(f"FAISS search failed: {e}")
                    results["steps"]["similar_routes"] = {
                        "status": "error",
                        "reason": str(e),
                        "routes": []
                    }
            else:
                results["steps"]["similar_routes"] = {
                    "status": "skipped",
                    "reason": "No embedding generated",
                    "routes": []
                }
            results["timing"]["similar_routes"] = time.time() - step_start
            results["tech_stack_used"].append("FAISS (Vector Search)")

            # Step 4: MIDI Generation (Mido) - Advanced Music Generation
            step_start = time.time()
            
            # Generate real MIDI using Mido library with advanced harmony
            from mido import MidiFile, MidiTrack, Message, MetaMessage, bpm2tempo
            import random
            
            # Define musical scales for different route characteristics
            SCALES = {
                "major": [0, 2, 4, 5, 7, 9, 11],  # Happy, bright
                "minor": [0, 2, 3, 5, 7, 8, 10],  # Melancholic
                "pentatonic": [0, 2, 4, 7, 9],    # Asian, simple
                "blues": [0, 3, 5, 6, 7, 10],     # Bluesy
                "dorian": [0, 2, 3, 5, 7, 9, 10], # Jazz-like
                "phrygian": [0, 1, 3, 5, 7, 8, 10] # Spanish, exotic
            }
            
            # Choose scale based on route characteristics
            lat_range = abs(float(destination_airport.latitude) - float(origin_airport.latitude))
            lon_range = abs(float(destination_airport.longitude) - float(origin_airport.longitude))
            distance_km = route_data.get("total_distance_km", 1000)
            
            # Select scale based on music_style or route characteristics
            if music_style in SCALES:
                scale = SCALES[music_style]
                scale_name = music_style
            elif lat_range > 90:  # Long north-south journey
                scale = SCALES["minor"]
                scale_name = "minor"
            elif lon_range > 120:  # Long east-west journey
                scale = SCALES["pentatonic"]
                scale_name = "pentatonic"
            elif distance_km > 8000:  # Very long haul
                scale = SCALES["dorian"]
                scale_name = "dorian"
            else:
                scale = SCALES["major"]
                scale_name = "major"
            
            logger.info(f"Selected scale: {scale_name} for route characteristics")
            
            # Create MIDI file with multiple tracks
            mid = MidiFile()
            melody_track = MidiTrack()
            harmony_track = MidiTrack()
            bass_track = MidiTrack()
            mid.tracks.append(melody_track)
            mid.tracks.append(harmony_track)
            mid.tracks.append(bass_track)
            
            # Set tempo based on route characteristics
            route_tempo = tempo
            if distance_km > 8000:  # Very long haul
                route_tempo = max(70, tempo - 30)  # Much slower, ambient
            elif distance_km > 5000:  # Long haul
                route_tempo = max(80, tempo - 20)  # Slower
            elif distance_km < 1000:  # Short haul
                route_tempo = min(140, tempo + 20)  # Faster, energetic
            
            for track in [melody_track, harmony_track, bass_track]:
                track.append(MetaMessage('set_tempo', tempo=bpm2tempo(route_tempo), time=0))
            
            # Calculate duration
            logger.info(f"Route distance for duration calculation: {distance_km} km")
            if distance_km <= 0:
                distance_km = 1000
                logger.warning("Invalid distance detected, using default 1000km")
            
            raw_duration = distance_km / 500
            duration_seconds = round(min(30, max(10, raw_duration)), 2)
            logger.info(f"Duration calculation: {distance_km}km / 500 = {raw_duration}s -> final: {duration_seconds}s")
            
            # Determine root note based on origin coordinates
            origin_lat = float(origin_airport.latitude)
            origin_lon = float(origin_airport.longitude)
            dest_lat = float(destination_airport.latitude)
            dest_lon = float(destination_airport.longitude)
            
            # Root note: C3 to C5 based on latitude
            root_note = 48 + int((origin_lat + 90) / 180 * 24)  # MIDI 48-72
            
            ticks_per_beat = 480
            note_count = 0
            notes_data = []
            
            # Generate melody with variation - UNIQUE for each route
            num_notes = int(duration_seconds * 2)  # 2 notes per second
            
            # Create unique seed based on route to ensure different compositions
            import hashlib
            route_seed = int(hashlib.md5(f"{origin}{destination}{distance_km}".encode()).hexdigest()[:8], 16)
            random.seed(route_seed)
            
            for i in range(num_notes):
                progress = i / num_notes
                
                # Interpolate position along route
                current_lat = origin_lat + (dest_lat - origin_lat) * progress
                current_lon = origin_lon + (dest_lon - origin_lon) * progress
                
                # Map latitude to scale degree with more variation
                lat_normalized = (current_lat + 90) / 180  # 0 to 1
                # Add route-specific variation to scale degree selection
                lat_variation = (lat_normalized + (distance_km % 100) / 100) % 1.0
                scale_degree = int(lat_variation * len(scale)) % len(scale)
                
                # Map longitude to octave variation with route-specific offset
                lon_normalized = (current_lon + 180) / 360  # 0 to 1
                lon_variation = (lon_normalized + (route_seed % 100) / 100) % 1.0
                octave_shift = int(lon_variation * 3) * 12  # 0, 12, 24, or 36 semitones
                
                # Create melody note with unique characteristics
                melody_note = root_note + scale[scale_degree] + octave_shift
                
                # Velocity varies with distance traveled and route characteristics
                base_velocity = 70 + int(progress * 30)  # 70-100
                velocity_variation = int((distance_km % 50) / 5)  # Route-specific variation
                velocity = min(127, max(40, base_velocity + random.randint(-10, 10) + velocity_variation))
                
                # Note timing with slight variation
                note_time = int(i * ticks_per_beat / 2)
                note_duration = ticks_per_beat // 2 + random.randint(-50, 50)
                
                # Add melody note
                melody_track.append(Message('note_on', note=melody_note, velocity=velocity, time=note_time))
                melody_track.append(Message('note_off', note=melody_note, velocity=0, time=note_time + note_duration))
                
                notes_data.append({
                    "note": int(melody_note),
                    "velocity": int(velocity),
                    "time": note_time,
                    "duration": note_duration,
                    "type": "melody"
                })
                note_count += 1
                
                # Add harmony (every 4th note) - UNIQUE intervals based on route
                harmony_interval = 3 + (route_seed % 3)  # Vary between 3rd, 4th, and 5th intervals
                if i % harmony_interval == 0:
                    # Vary harmony intervals based on route characteristics
                    harmony_offset = 2 if distance_km < 3000 else (3 if distance_km < 6000 else 4)
                    harmony_degree = (scale_degree + harmony_offset) % len(scale)
                    harmony_note = root_note + scale[harmony_degree] + octave_shift
                    harmony_velocity = velocity - 20 - int((route_seed % 10))
                    
                    harmony_track.append(Message('note_on', note=harmony_note, velocity=harmony_velocity, time=note_time))
                    harmony_track.append(Message('note_off', note=harmony_note, velocity=0, time=note_time + note_duration * 2))
                    
                    notes_data.append({
                        "note": int(harmony_note),
                        "velocity": int(harmony_velocity),
                        "time": note_time,
                        "duration": note_duration * 2,
                        "type": "harmony"
                    })
                    note_count += 1
                
                # Add bass (every 8th note) - UNIQUE patterns based on route
                bass_interval = 7 + (route_seed % 4)  # Vary between 7, 8, 9, 10 note intervals
                if i % bass_interval == 0:
                    # Vary bass notes based on route distance
                    bass_scale_degree = 0 if distance_km < 4000 else (4 if distance_km < 8000 else 2)
                    bass_note = root_note - 12 + scale[bass_scale_degree]  # Root note one octave down
                    bass_velocity = 75 + int((route_seed % 15))
                    
                    bass_track.append(Message('note_on', note=bass_note, velocity=bass_velocity, time=note_time))
                    bass_track.append(Message('note_off', note=bass_note, velocity=0, time=note_time + ticks_per_beat * 2))
                    
                    notes_data.append({
                        "note": int(bass_note),
                        "velocity": int(bass_velocity),
                        "time": note_time,
                        "duration": ticks_per_beat * 2,
                        "type": "bass"
                    })
                    note_count += 1
            
            # Save MIDI file (create directory if it doesn't exist)
            import os
            midi_dir = "midi_output"
            os.makedirs(midi_dir, exist_ok=True)
            
            midi_filename = f"route_{origin}_{destination}_{int(time.time())}.mid"
            midi_path = os.path.join(midi_dir, midi_filename)
            
            try:
                mid.save(midi_path)
                midi_saved = True
            except Exception as e:
                logger.warning(f"Failed to save MIDI file: {e}")
                midi_saved = False
                midi_filename = "not_saved"
            
            music_data = {
                "composition_id": int(time.time()),
                "duration_seconds": duration_seconds,
                "note_count": note_count,
                "tempo": route_tempo,
                "midi_file": midi_filename,
                "midi_saved": midi_saved,
                "key": "C",
                "scale": scale_name,
                "root_note": root_note,
                "tracks": {
                    "melody": sum(1 for n in notes_data if n.get("type") == "melody"),
                    "harmony": sum(1 for n in notes_data if n.get("type") == "harmony"),
                    "bass": sum(1 for n in notes_data if n.get("type") == "bass")
                },
                "notes": notes_data  # Include actual note data with types
            }
            
            # Save composition to database
            try:
                from app.models.models import MusicComposition
                
                # Get or create route record
                route_record = await db.execute(
                    select(Route).where(
                        and_(
                            Route.origin_airport_id == origin_airport.id,
                            Route.destination_airport_id == destination_airport.id
                        )
                    ).limit(1)
                )
                route_record = route_record.scalar_one_or_none()
                
                if not route_record:
                    # Create new route
                    route_record = Route(
                        origin_airport_id=origin_airport.id,
                        destination_airport_id=destination_airport.id,
                        distance_km=route_data.get("total_distance_km", 0),
                        duration_min=int(route_data.get("total_duration_min", 0))
                    )
                    db.add(route_record)
                    await db.flush()
                
                # Calculate complexity based on route and music characteristics
                complexity = min(1.0, (
                    (distance_km / 10000) * 0.3 +  # Distance factor
                    (lat_range / 180) * 0.3 +       # Latitude variation
                    (lon_range / 360) * 0.2 +       # Longitude variation
                    (note_count / 100) * 0.2        # Note density
                ))
                
                # Create composition record
                composition = MusicComposition(
                    route_id=route_record.id,
                    tempo=route_tempo,
                    pitch=float(root_note),
                    harmony=0.8,  # Higher harmony with multiple tracks
                    midi_path=midi_path,
                    complexity_score=complexity,
                    harmonic_richness=0.85,  # Rich harmony with melody + harmony + bass
                    duration_seconds=int(duration_seconds),
                    unique_notes=note_count,
                    musical_key="C",
                    scale=scale_name,
                    genre=scale_name,
                    is_public=True
                )
                db.add(composition)
                await db.commit()
                await db.refresh(composition)
                
                # Update composition_id with actual database ID
                music_data["composition_id"] = composition.id
                music_data["db_saved"] = True
                
                logger.info(f"Saved composition {composition.id} to database")
                
            except Exception as e:
                logger.error(f"Failed to save composition to database: {e}")
                music_data["db_saved"] = False
            
            # Log the tracks data for debugging
            tracks_data = music_data.get("tracks", {}) if music_data else {}
            logger.info(f"Tracks data being sent: {tracks_data}")
            logger.info(f"Scale: {music_data.get('scale', scale_name) if music_data else scale_name}")
            logger.info(f"Root note: {music_data.get('root_note', root_note) if music_data else root_note}")
            
            results["steps"]["midi_generation"] = {
                "status": "success" if music_data else "failed",
                "composition_id": music_data.get("composition_id") if music_data else None,
                "duration_seconds": music_data.get("duration_seconds", 0) if music_data else 0,
                "note_count": music_data.get("note_count", 0) if music_data else 0,
                "notes": notes_data,  # Include notes in response
                "scale": music_data.get("scale", scale_name) if music_data else scale_name,
                "root_note": music_data.get("root_note", root_note) if music_data else root_note,
                "tracks": tracks_data,
                "db_saved": music_data.get("db_saved", False)
            }
            results["timing"]["midi_generation"] = time.time() - step_start
            results["tech_stack_used"].append("Mido (MIDI Generation)")

            # Step 5: Redis Pub/Sub Broadcast
            step_start = time.time()
            # Safely extract similar routes for broadcast
            similar_routes_list = []
            if "similar_routes" in results["steps"] and "routes" in results["steps"]["similar_routes"]:
                similar_routes_list = [
                    f"{r.get('origin', 'unknown')}-{r.get('destination', 'unknown')}" 
                    for r in results["steps"]["similar_routes"]["routes"] 
                    if r and isinstance(r, dict)
                ]
            
            broadcast_data = {
                "event": "demo_composition_generated",
                "route": f"{origin}-{destination}",
                "composition_id": music_data.get("composition_id") if music_data else None,
                "duration_seconds": music_data.get("duration_seconds", 0),
                "note_count": music_data.get("note_count", 0),
                "tempo": music_data.get("tempo", tempo),
                "similar_routes": similar_routes_list,
                "demo_id": results["demo_id"],
                "db_saved": music_data.get("db_saved", False),
                "timestamp": datetime.utcnow().isoformat()
            }
            
            subscribers = self.publisher.publish_music_generated(
                route_id=f"{origin}_{destination}",
                user_id="demo_user",
                music_data=broadcast_data
            )
            
            # Also cache the composition in Redis for quick retrieval
            try:
                from app.services.cache import get_cache
                import json
                cache = get_cache()
                
                # Create comprehensive cache data with visible update tracking
                current_timestamp = datetime.utcnow()
                cache_data = {
                    "composition_id": music_data.get("composition_id"),
                    "origin": origin,
                    "destination": destination,
                    "notes": notes_data,
                    "duration_seconds": duration_seconds,
                    "note_count": note_count,
                    "tempo": route_tempo,
                    "key": "C",
                    "scale": music_style,
                    "midi_file": midi_filename,
                    "generated_at": current_timestamp.isoformat(),
                    "unix_timestamp": int(current_timestamp.timestamp()),
                    "update_id": f"{origin}_{destination}_{int(current_timestamp.timestamp())}"
                }
                
                # Save with multiple readable keys for easy access in Redis Insight
                if cache.redis_client:
                    # Key 1: Route-based key
                    route_key = f"aero:music:{origin}:{destination}"
                    cache.redis_client.setex(route_key, 3600, json.dumps(cache_data, default=str))
                    logger.info(f"Cached composition in Redis: {route_key}")
                    
                    # Key 2: Composition ID key
                    comp_key = f"aero:composition:{music_data.get('composition_id')}"
                    cache.redis_client.setex(comp_key, 3600, json.dumps(cache_data, default=str))
                    logger.info(f"Cached composition in Redis: {comp_key}")
                    
                    # Key 3: Latest generation key (for quick access to most recent)
                    latest_key = f"aero:latest:music"
                    
                    # Increment update counter to make changes visible in Redis Insight
                    counter_key = f"aero:latest:music:counter"
                    update_count = cache.redis_client.incr(counter_key)
                    cache.redis_client.expire(counter_key, 3600)
                    
                    # Add counter to cache data for visibility
                    cache_data["update_count"] = update_count
                    
                    cache.redis_client.setex(latest_key, 3600, json.dumps(cache_data, default=str))
                    logger.info(f"Cached latest composition in Redis: {latest_key} (update #{update_count})")
                    
                    # Also use the cache service method
                    cache.set_route_music(origin, destination, cache_data)
                    
            except Exception as e:
                logger.warning(f"Failed to cache composition in Redis: {e}")
            
            results["steps"]["redis_broadcast"] = {
                "status": "success",
                "subscribers_notified": subscribers,
                "channels": ["music:generated"]
            }
            results["timing"]["redis_broadcast"] = time.time() - step_start
            results["tech_stack_used"].append("Redis (Pub/Sub Broadcasting)")

            # Step 6: Galera Cluster Sync (Skipped - Optional Component)
            step_start = time.time()
            results["steps"]["galera_sync"] = {
                "status": "skipped",
                "reason": "Galera cluster sync is optional for demo",
                "cluster_nodes": 1,
                "sync_status": "Single-node mode"
            }
            results["timing"]["galera_sync"] = time.time() - step_start
            results["tech_stack_used"].append("Galera Cluster (Multi-node Sync - Skipped)")

            # Step 7: DuckDB Analytics - Real Analytics from OpenFlights Data
            step_start = time.time()
            
            # Log real analytics data from OpenFlights dataset
            if route_data:
                complexity_score = (
                    (route_data.get("total_distance_km", 0) / 10000) * 0.4 +  # Distance factor
                    (route_data.get("num_stops", 0) / 5) * 0.3 +  # Stops factor
                    (abs(float(destination_airport.latitude) - float(origin_airport.latitude)) / 180) * 0.3  # Latitude change factor
                )
                
                self.analytics.log_route_analytics(
                    origin=origin,
                    destination=destination,
                    distance_km=route_data.get("total_distance_km", 0),
                    complexity_score=min(1.0, complexity_score),
                    path_length=len(route_data.get("path", [])),
                    intermediate_stops=route_data.get("num_stops", 0)
                )

            if music_data:
                self.analytics.log_music_analytics(
                    route_id=music_data.get("composition_id", 0),
                    tempo=tempo,
                    key="C",
                    scale=music_style,
                    duration_seconds=music_data.get("duration_seconds", 0),
                    note_count=music_data.get("note_count", 0),
                    harmony_complexity=0.7,
                    genre=music_style,
                    embedding_vector=embedding or []
                )

            # Get analytics insights
            complexity_stats = self.analytics.get_route_complexity_stats()
            genre_distribution = self.analytics.get_genre_distribution()
            
            results["steps"]["duckdb_analytics"] = {
                "status": "success",
                "insights": {
                    "total_routes_analyzed": complexity_stats.get("total_routes", 0),
                    "avg_complexity": complexity_stats.get("avg_complexity", 0),
                    "genre_distribution": dict(list(genre_distribution.items())[:3])  # Top 3 genres
                }
            }
            results["timing"]["duckdb_analytics"] = time.time() - step_start
            results["tech_stack_used"].append("DuckDB (Real-time Analytics)")

            # Overall demo timing
            results["timing"]["total_demo_time"] = time.time() - demo_start
            results["demo_status"] = "success"
            
            # Add composition data to top level for easier access
            results["composition"] = music_data

            return results

        except Exception as e:
            logger.error(f"Demo flow error: {e}")
            results["demo_status"] = "error"
            results["error"] = str(e)
            results["timing"]["total_demo_time"] = time.time() - demo_start
            return results


# Global demo orchestrator
demo_orchestrator = DemoOrchestrator()


@router.get("/complete-demo")
async def run_complete_demo(
    origin: str = Query(..., description="Origin airport code (e.g., DEL)"),
    destination: str = Query(..., description="Destination airport code (e.g., LHR)"),
    music_style: str = Query("ambient", description="Music style for generation"),
    tempo: int = Query(120, ge=60, le=200, description="Tempo in BPM"),
    background_tasks: BackgroundTasks = None,
    db: AsyncSession = Depends(get_db)
):
    """
    🎵 Complete Tech Stack Demo Flow
    
    Demonstrates the entire pipeline:
    1. Route computation (NetworkX + Dijkstra)
    2. Vector embedding (PyTorch)
    3. Similar routes (FAISS vector search)
    4. MIDI generation (Mido)
    5. Redis Pub/Sub broadcasting
    6. Galera cluster sync
    7. DuckDB analytics computation
    
    Example: GET /demo/complete-demo?origin=DEL&destination=LHR&music_style=ambient&tempo=120
    """
    try:
        # Run the complete demo with real OpenFlights data
        results = await demo_orchestrator.run_complete_demo(
            origin=origin,
            destination=destination,
            music_style=music_style,
            tempo=tempo,
            db=db
        )

        return {
            "message": f"🎵 Complete demo executed for {origin} → {destination}",
            "demo_results": results,
            "tech_stack_showcase": {
                "database": "MariaDB with OpenFlights dataset (3K+ airports, 67K+ routes)",
                "vector_search": "FAISS (free alternative to paid vector DBs)",
                "analytics": "DuckDB (fast, lightweight SQL engine)",
                "ai_embeddings": "PyTorch (route → sound embeddings)",
                "music_generation": "Mido (route → MIDI conversion)",
                "real_time_sync": "Galera Cluster (multi-node sync)",
                "caching_streaming": "Redis Stack (Pub/Sub + caching)",
                "api_layer": "FastAPI (high-performance async API)"
            },
            "demo_flow_summary": {
                "step_1": "Choose airports (DEL → LHR)",
                "step_2": "Compute route path using NetworkX + Dijkstra",
                "step_3": "Generate vector embeddings with PyTorch",
                "step_4": "Find similar routes using FAISS search",
                "step_5": "Generate real-time MIDI with Mido",
                "step_6": "Broadcast via Redis Pub/Sub",
                "step_7": "Sync across Galera cluster nodes",
                "step_8": "Compute analytics with DuckDB"
            }
        }

    except Exception as e:
        logger.error(f"Complete demo error: {e}")
        raise HTTPException(status_code=500, detail=f"Demo execution failed: {str(e)}")


@router.get("/tech-stack-status")
async def get_tech_stack_status():
    """
    📊 Tech Stack Health Check
    
    Verifies all components of the tech stack are working:
    - MariaDB connection
    - Redis connectivity  
    - DuckDB analytics
    - FAISS vector search
    - Galera cluster status
    """
    try:
        status = {
            "timestamp": datetime.utcnow().isoformat(),
            "overall_status": "healthy",
            "components": {}
        }

        # Check Redis
        try:
            cache = get_cache()
            redis_info = cache.get_storage_info()
            status["components"]["redis"] = {
                "status": "connected" if redis_info.get("connected") else "disconnected",
                "memory_usage": redis_info.get("memory_used_mb", 0),
                "details": "Redis Stack (Pub/Sub + Caching)"
            }
        except Exception as e:
            status["components"]["redis"] = {"status": "error", "error": str(e)}

        # Check FAISS
        try:
            faiss_service = get_faiss_duckdb_service()
            faiss_stats = faiss_service.get_statistics()
            status["components"]["faiss"] = {
                "status": "ready",
                "vectors_indexed": faiss_stats.get("total_vectors", 0),
                "details": "FAISS (free vector search alternative)"
            }
        except Exception as e:
            status["components"]["faiss"] = {"status": "error", "error": str(e)}

        # Check DuckDB
        try:
            analytics = get_analytics()
            duck_stats = analytics.get_route_complexity_stats()
            status["components"]["duckdb"] = {
                "status": "ready",
                "routes_analyzed": duck_stats.get("total_routes", 0),
                "details": "DuckDB (fast analytics engine)"
            }
        except Exception as e:
            status["components"]["duckdb"] = {"status": "error", "error": str(e)}

        # Check Galera (Skipped - Optional Component)
        try:
            status["components"]["galera"] = {
                "status": "skipped",
                "note": "Galera cluster sync is optional for demo",
                "details": "Galera Cluster (multi-node sync - Skipped)"
            }
        except Exception as e:
            status["components"]["galera"] = {"status": "skipped", "note": "Galera not configured"}

        # Check PyTorch
        try:
            import torch
            status["components"]["pytorch"] = {
                "status": "ready",
                "version": torch.__version__,
                "details": "PyTorch (AI embeddings & harmony generation)"
            }
        except Exception as e:
            status["components"]["pytorch"] = {"status": "error", "error": str(e)}

        # Check Mido
        try:
            import mido
            status["components"]["mido"] = {
                "status": "ready",
                "details": "Mido (MIDI generation library)"
            }
        except Exception as e:
            status["components"]["mido"] = {"status": "error", "error": str(e)}

        # Check NetworkX
        try:
            import networkx as nx
            status["components"]["networkx"] = {
                "status": "ready",
                "version": nx.__version__,
                "details": "NetworkX (graph pathfinding & Dijkstra)"
            }
        except Exception as e:
            status["components"]["networkx"] = {"status": "error", "error": str(e)}

        # Determine overall status
        error_count = sum(1 for comp in status["components"].values() if comp["status"] == "error")
        if error_count > 0:
            status["overall_status"] = "degraded"
        if error_count > 3:
            status["overall_status"] = "unhealthy"

        return status

    except Exception as e:
        logger.error(f"Tech stack status check error: {e}")
        raise HTTPException(status_code=500, detail=f"Status check failed: {str(e)}")


@router.get("/demo-examples")
async def get_demo_examples():
    """
    🎯 Demo Examples & Use Cases
    
    Provides ready-to-use examples for demonstrating the tech stack
    """
    return {
        "popular_routes": [
            {
                "name": "Delhi to London",
                "origin": "DEL",
                "destination": "LHR",
                "description": "Long-haul international route with complex harmonies",
                "expected_features": "Rich orchestral composition, multiple key changes"
            },
            {
                "name": "New York to Los Angeles", 
                "origin": "JFK",
                "destination": "LAX",
                "description": "Cross-continental US route with steady rhythms",
                "expected_features": "Steady 4/4 time, major key progressions"
            },
            {
                "name": "Tokyo to Sydney",
                "origin": "NRT", 
                "destination": "SYD",
                "description": "Trans-Pacific route with ambient textures",
                "expected_features": "Ethereal pads, pentatonic scales"
            },
            {
                "name": "London to Paris",
                "origin": "LHR",
                "destination": "CDG", 
                "description": "Short European route with classical elements",
                "expected_features": "Chamber music style, baroque influences"
            }
        ],
        "music_styles": [
            "ambient", "classical", "electronic", "jazz", "world", "cinematic"
        ],
        "demo_commands": {
            "complete_demo": "GET /demo/complete-demo?origin=DEL&destination=LHR&music_style=ambient&tempo=120",
            "tech_status": "GET /demo/tech-stack-status",
            "examples": "GET /demo/demo-examples"
        },
        "tech_stack_highlights": {
            "real_time_features": "Redis Pub/Sub broadcasts new compositions instantly",
            "ai_powered": "PyTorch generates route embeddings for semantic similarity",
            "scalable_search": "FAISS enables fast vector similarity without paid services", 
            "analytics_ready": "DuckDB computes pitch complexity by continent in real-time",
            "multi_node_sync": "Galera ensures data consistency across team laptops",
            "production_ready": "FastAPI provides high-performance async endpoints"
        }
    }


@router.get("/redis-pubsub-info")
async def get_redis_pubsub_info():
    """
    📡 Redis Pub/Sub Information
    
    Explains why you see "0 subscribers" and how to test Redis Pub/Sub functionality
    """
    return {
        "redis_pubsub_explanation": {
            "why_0_subscribers": "This is normal! It means no clients are currently subscribed to Redis channels",
            "how_pubsub_works": [
                "Publishers send messages to channels",
                "Subscribers listen to specific channels", 
                "Messages are only delivered to active subscribers",
                "If no one is listening, subscriber count = 0"
            ],
            "testing_pubsub": {
                "method_1": "Use Redis CLI: redis-cli SUBSCRIBE music:generated",
                "method_2": "Use RedisInsight GUI to monitor channels",
                "method_3": "Create a WebSocket client to subscribe",
                "method_4": "Use the test subscriber endpoint below"
            }
        },
        "active_channels": [
            "music:generated - New compositions",
            "routes:cached - Route cache events", 
            "system:status - System health updates",
            "vector:search:public - Vector search results",
            "generation:progress:public - Music generation progress"
        ],
        "demo_channels_used": [
            "music:generated - When demo completes music generation",
            "system:status - For health check broadcasts",
            "vector:search:public - For similarity search results"
        ],
        "real_world_usage": [
            "Frontend apps subscribe to get real-time updates",
            "Multiple users can collaborate on music generation",
            "Live dashboards show generation progress",
            "Mobile apps get push notifications via Redis"
        ]
    }


@router.get("/test-redis-subscriber")
async def test_redis_subscriber():
    """
    🧪 Test Redis Subscriber
    
    Creates a temporary subscriber to demonstrate Pub/Sub functionality
    """
    try:
        import redis
        from app.core.config import settings
        import json
        
        # Create Redis client
        redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True)
        
        # Test publishing a message
        test_message = {
            "event": "test_message",
            "timestamp": datetime.utcnow().isoformat(),
            "message": "This is a test of Redis Pub/Sub functionality",
            "demo": True
        }
        
        # Publish to test channel
        subscribers = redis_client.publish("demo:test", json.dumps(test_message))
        
        # Get Redis info
        redis_info = redis_client.info()
        
        return {
            "test_result": "success",
            "message_published": test_message,
            "subscribers_reached": subscribers,
            "explanation": "If subscribers_reached = 0, it means no clients are listening to 'demo:test' channel",
            "redis_status": {
                "connected_clients": redis_info.get("connected_clients", 0),
                "total_commands": redis_info.get("total_commands_processed", 0),
                "memory_used": redis_info.get("used_memory_human", "unknown")
            },
            "how_to_subscribe": [
                "Redis CLI: redis-cli SUBSCRIBE demo:test",
                "Python: redis_client.subscribe('demo:test')",
                "Node.js: redisClient.subscribe('demo:test')",
                "WebSocket: Connect to Redis Pub/Sub bridge"
            ]
        }
        
    except Exception as e:
        return {
            "test_result": "error",
            "error": str(e),
            "note": "This is expected if Redis is not running or not configured"
        }

@router.get("/openflights-data-check")
async def check_openflights_data(db: AsyncSession = Depends(get_db)):
    """
    🔍 OpenFlights Data Check
    
    Verifies that the OpenFlights dataset is properly loaded and accessible
    """
    try:
        # Count total airports
        airports_result = await db.execute(select(Airport))
        airports = airports_result.scalars().all()
        
        # Count airports with valid IATA codes
        valid_airports = [a for a in airports if a.iata_code and a.iata_code.strip() != ""]
        
        # Count airports with coordinates
        airports_with_coords = [a for a in valid_airports if a.latitude is not None and a.longitude is not None]
        
        # Count total routes
        routes_result = await db.execute(select(Route))
        routes = routes_result.scalars().all()
        
        # Sample some airports
        sample_airports = []
        for airport in airports_with_coords[:5]:
            sample_airports.append({
                "iata_code": airport.iata_code,
                "name": airport.name,
                "city": airport.city,
                "country": airport.country,
                "latitude": airport.latitude,
                "longitude": airport.longitude
            })
        
        # Check specific airports (DEL, LHR)
        del_airport = await db.execute(
            select(Airport).where(Airport.iata_code == "DEL").limit(1)
        )
        del_airport = del_airport.scalar_one_or_none()
        
        lhr_airport = await db.execute(
            select(Airport).where(Airport.iata_code == "LHR").limit(1)
        )
        lhr_airport = lhr_airport.scalar_one_or_none()
        
        return {
            "openflights_data_status": "loaded",
            "dataset_info": {
                "total_airports": len(airports),
                "airports_with_iata": len(valid_airports),
                "airports_with_coordinates": len(airports_with_coords),
                "total_routes": len(routes),
                "data_quality": f"{len(airports_with_coords)/len(airports)*100:.1f}% airports have complete data"
            },
            "sample_airports": sample_airports,
            "test_airports": {
                "DEL_found": del_airport is not None,
                "DEL_details": {
                    "name": del_airport.name if del_airport else None,
                    "city": del_airport.city if del_airport else None,
                    "country": del_airport.country if del_airport else None
                } if del_airport else None,
                "LHR_found": lhr_airport is not None,
                "LHR_details": {
                    "name": lhr_airport.name if lhr_airport else None,
                    "city": lhr_airport.city if lhr_airport else None,
                    "country": lhr_airport.country if lhr_airport else None
                } if lhr_airport else None
            },
            "recommendations": [
                "✅ OpenFlights dataset appears to be loaded" if len(airports) > 1000 else "❌ Dataset may not be fully loaded",
                f"✅ {len(valid_airports)} airports have IATA codes" if len(valid_airports) > 1000 else "❌ Many airports missing IATA codes",
                f"✅ {len(airports_with_coords)} airports have coordinates" if len(airports_with_coords) > 1000 else "❌ Many airports missing coordinates",
                "✅ Ready for route pathfinding" if del_airport and lhr_airport else "❌ Test airports (DEL/LHR) not found"
            ]
        }
        
    except Exception as e:
        return {
            "openflights_data_status": "error",
            "error": str(e),
            "recommendations": [
                "❌ Database connection failed or OpenFlights data not loaded",
                "💡 Check if database is running and populated with OpenFlights dataset",
                "💡 Run data import scripts to load airports and routes"
            ]
        }


@router.get("/quick-demo")
async def run_quick_demo(
    origin: str = Query(..., description="Origin airport code (e.g., DEL)"),
    destination: str = Query(..., description="Destination airport code (e.g., LHR)"),
    db: AsyncSession = Depends(get_db)
):
    """
    ⚡ Quick Demo - Lightweight Version
    
    Fast demonstration of core functionality without heavy operations.
    Use this to test if the basic pipeline works before running the full demo.
    """
    try:
        start_time = time.time()
        
        # Step 1: Get airports from OpenFlights dataset
        origin_airport = await db.execute(
            select(Airport).where(Airport.iata_code == origin).limit(1)
        )
        origin_airport = origin_airport.scalar_one_or_none()
        
        destination_airport = await db.execute(
            select(Airport).where(Airport.iata_code == destination).limit(1)
        )
        destination_airport = destination_airport.scalar_one_or_none()
        
        if not origin_airport or not destination_airport:
            raise HTTPException(status_code=404, detail=f"Airport not found: {origin} or {destination}")
        
        # Step 2: Calculate basic route info
        import math
        
        def haversine_distance(lat1, lon1, lat2, lon2):
            R = 6371  # Earth's radius in kilometers
            lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])
            dlat = lat2 - lat1
            dlon = lon2 - lon1
            a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
            c = 2 * math.asin(math.sqrt(a))
            return R * c
        
        distance = haversine_distance(
            origin_airport.latitude, origin_airport.longitude,
            destination_airport.latitude, destination_airport.longitude
        )
        
        # Step 3: Generate simple PyTorch embedding
        import torch
        route_features = torch.tensor([
            float(origin_airport.latitude),
            float(origin_airport.longitude),
            float(destination_airport.latitude),
            float(destination_airport.longitude),
            float(distance),
            0.0  # num_stops
        ], dtype=torch.float32)
        
        # Simple embedding
        with torch.no_grad():
            embedding = torch.nn.functional.normalize(route_features, dim=0).tolist()
        
        # Step 4: Create basic MIDI info (without saving file)
        from mido import bpm2tempo
        tempo = 120
        duration = min(10, distance / 1000)  # Max 10 seconds
        note_count = int(duration * 4)  # 4 notes per second
        
        # Step 5: Log to analytics
        analytics = get_analytics()
        analytics.log_route_analytics(
            origin=origin,
            destination=destination,
            distance_km=distance,
            complexity_score=min(1.0, distance / 10000),
            path_length=2,
            intermediate_stops=0
        )
        
        # Step 6: Publish Redis message
        publisher = get_publisher()
        subscribers = publisher.publish_music_generated(
            route_id=f"{origin}_{destination}",
            user_id="demo_user",
            music_data={
                "route": f"{origin}-{destination}",
                "distance_km": distance,
                "duration_seconds": duration,
                "note_count": note_count
            }
        )
        
        execution_time = time.time() - start_time
        
        return {
            "demo_type": "quick_demo",
            "status": "success",
            "execution_time_ms": round(execution_time * 1000, 2),
            "route_info": {
                "origin": {
                    "code": origin_airport.iata_code,
                    "name": origin_airport.name,
                    "city": origin_airport.city,
                    "country": origin_airport.country,
                    "coordinates": [origin_airport.latitude, origin_airport.longitude]
                },
                "destination": {
                    "code": destination_airport.iata_code,
                    "name": destination_airport.name,
                    "city": destination_airport.city,
                    "country": destination_airport.country,
                    "coordinates": [destination_airport.latitude, destination_airport.longitude]
                },
                "distance_km": round(distance, 2),
                "estimated_flight_time_hours": round(distance / 800, 2)
            },
            "tech_stack_demo": {
                "openflights_data": "✅ Real airport data loaded",
                "pytorch_embedding": f"✅ Generated {len(embedding)}-dimensional vector",
                "mido_midi": f"✅ Calculated {note_count} notes for {duration:.1f}s composition",
                "duckdb_analytics": "✅ Route logged to analytics database",
                "redis_pubsub": f"✅ Published to {subscribers} subscribers"
            },
            "next_steps": [
                "✅ Quick demo successful - basic pipeline working",
                "🎵 Try full demo: GET /demo/complete-demo?origin=DEL&destination=LHR",
                "📊 Check analytics: GET /analytics-showcase/real-time-composition-metrics",
                "🔌 Test WebSocket: GET /demo/websocket-info"
            ]
        }
        
    except Exception as e:
        logger.error(f"Quick demo error: {e}")
        return {
            "demo_type": "quick_demo",
            "status": "error",
            "error": str(e),
            "troubleshooting": [
                "❌ Check if OpenFlights data is loaded",
                "❌ Verify database connection",
                "❌ Check if airports exist in dataset",
                "💡 Try: GET /demo/openflights-data-check"
            ]
        }

@router.get("/debug-test")
async def debug_test():
    """
    🐛 Debug Test - Simple endpoint to test basic functionality
    """
    try:
        import torch
        import mido
        import numpy as np
        from datetime import datetime
        
        return {
            "status": "success",
            "timestamp": datetime.utcnow().isoformat(),
            "imports": {
                "torch": torch.__version__,
                "mido": "available",
                "numpy": np.__version__
            },
            "basic_operations": {
                "torch_tensor": "✅ Can create tensors",
                "mido_file": "✅ Can create MIDI files",
                "numpy_array": "✅ Can create arrays"
            }
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "error_type": type(e).__name__
        }


@router.get("/db-test")
async def db_test(db: AsyncSession = Depends(get_db)):
    """
    🗄️ Database Test - Test database connection and basic queries
    """
    try:
        # Test basic database connection
        result = await db.execute(select(Airport).limit(1))
        airport = result.scalar_one_or_none()
        
        if airport:
            return {
                "status": "success",
                "database": "connected",
                "sample_airport": {
                    "iata_code": airport.iata_code,
                    "name": airport.name,
                    "city": airport.city,
                    "country": airport.country
                }
            }
        else:
            return {
                "status": "warning",
                "database": "connected_but_empty",
                "message": "Database connected but no airports found"
            }
            
    except Exception as e:
        return {
            "status": "error",
            "database": "connection_failed",
            "error": str(e),
            "error_type": type(e).__name__
        }


@router.get("/simple-demo")
async def run_simple_demo(
    origin: str = Query(..., description="Origin airport code (e.g., DEL)"),
    destination: str = Query(..., description="Destination airport code (e.g., LHR)"),
    db: AsyncSession = Depends(get_db)
):
    """
    🎯 Simple Demo - Works with Your Existing Database
    
    Demonstrates the tech stack using your existing SQL tables without complex graph operations.
    This version is optimized for your current database setup.
    """
    try:
        start_time = time.time()
        logger.info(f"Starting simple demo for {origin} → {destination}")
        
        # Step 1: Get airports from your existing database
        origin_airport = await db.execute(
            select(Airport).where(Airport.iata_code == origin).limit(1)
        )
        origin_airport = origin_airport.scalar_one_or_none()
        
        destination_airport = await db.execute(
            select(Airport).where(Airport.iata_code == destination).limit(1)
        )
        destination_airport = destination_airport.scalar_one_or_none()
        
        if not origin_airport or not destination_airport:
            raise HTTPException(status_code=404, detail=f"Airport not found in your database: {origin} or {destination}")
        
        # Step 2: Check for direct route in your database
        direct_route = await db.execute(
            select(Route).where(
                and_(
                    Route.origin_airport_id == origin_airport.id,
                    Route.destination_airport_id == destination_airport.id
                )
            ).limit(1)
        )
        direct_route = direct_route.scalar_one_or_none()
        
        # Step 3: Calculate route metrics
        import math
        
        def haversine_distance(lat1, lon1, lat2, lon2):
            R = 6371  # Earth's radius in kilometers
            # Ensure all values are float before math operations
            lat1, lon1, lat2, lon2 = float(lat1), float(lon1), float(lat2), float(lon2)
            lat1, lon1, lat2, lon2 = math.radians(lat1), math.radians(lon1), math.radians(lat2), math.radians(lon2)
            dlat = lat2 - lat1
            dlon = lon2 - lon1
            a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
            c = 2 * math.asin(math.sqrt(a))
            return R * c
        
        calculated_distance = haversine_distance(
            origin_airport.latitude, origin_airport.longitude,
            destination_airport.latitude, destination_airport.longitude
        )
        
        # Use database route distance if available, otherwise calculated
        actual_distance = float(direct_route.distance_km) if direct_route and direct_route.distance_km else calculated_distance
        
        # Step 4: Generate PyTorch embedding from real data
        import torch
        route_features = torch.tensor([
            float(origin_airport.latitude),
            float(origin_airport.longitude),
            float(destination_airport.latitude),
            float(destination_airport.longitude),
            float(actual_distance),
            1.0 if direct_route else 0.0  # Direct route flag
        ], dtype=torch.float32)
        
        # Simple neural network for embedding
        with torch.no_grad():
            embedding = torch.nn.functional.normalize(route_features, dim=0)
            embedding_list = embedding.tolist()
        
        # Step 5: Generate MIDI composition
        from mido import MidiFile, MidiTrack, Message, MetaMessage, bpm2tempo
        
        mid = MidiFile()
        track = MidiTrack()
        mid.tracks.append(track)
        
        # Set tempo based on distance
        tempo = 120 if actual_distance < 5000 else 100  # Slower for long flights
        track.append(MetaMessage('set_tempo', tempo=bpm2tempo(tempo), time=0))
        
        # Generate notes based on coordinates - convert all to float
        # Ensure minimum duration for audible playback
        if actual_distance <= 0:
            actual_distance = 1000  # Default to 1000km if invalid
            logger.warning("Invalid actual_distance detected, using default 1000km")
        
        raw_duration = actual_distance / 1000
        duration_seconds = round(min(15, max(5, raw_duration)), 2)
        logger.info(f"Simple demo duration: {actual_distance}km / 1000 = {raw_duration}s -> final: {duration_seconds}s")
        origin_lat = float(origin_airport.latitude)
        dest_lat = float(destination_airport.latitude)
        base_note = 60 + int((origin_lat + 90) / 180 * 24) % 24
        
        note_count = 0
        for i in range(int(duration_seconds * 2)):  # 2 notes per second
            progress = i / (duration_seconds * 2)
            current_lat = origin_lat + (dest_lat - origin_lat) * progress
            note = base_note + int((current_lat + 90) / 180 * 12) % 12
            
            # Note on with proper timing
            note_time = int(i * 240)  # 240 ticks per beat at 120 BPM
            track.append(Message('note_on', note=note, velocity=64, time=note_time))
            track.append(Message('note_off', note=note, velocity=64, time=note_time + 240))  # Quarter beat
            note_count += 1
        
        # Save MIDI file
        import os
        midi_dir = "midi_output"
        os.makedirs(midi_dir, exist_ok=True)
        midi_filename = f"simple_{origin}_{destination}_{int(time.time())}.mid"
        midi_path = os.path.join(midi_dir, midi_filename)
        
        try:
            mid.save(midi_path)
            midi_saved = True
        except Exception as e:
            logger.warning(f"MIDI save failed: {e}")
            midi_saved = False
        
        # Step 6: Log to DuckDB analytics
        analytics = get_analytics()
        analytics.log_route_analytics(
            origin=origin,
            destination=destination,
            distance_km=actual_distance,
            complexity_score=min(1.0, actual_distance / 10000),
            path_length=2,
            intermediate_stops=0
        )
        
        # Step 7: Publish to Redis
        publisher = get_publisher()
        subscribers = publisher.publish_music_generated(
            route_id=f"{origin}_{destination}",
            user_id="demo_user",
            music_data={
                "route": f"{origin}-{destination}",
                "distance_km": actual_distance,
                "duration_seconds": duration_seconds,
                "note_count": note_count,
                "midi_file": midi_filename if midi_saved else "not_saved"
            }
        )
        
        execution_time = time.time() - start_time
        
        return {
            "demo_type": "simple_demo_with_real_data",
            "status": "success",
            "execution_time_ms": round(execution_time * 1000, 2),
            "database_info": {
                "using_existing_tables": True,
                "direct_route_found": direct_route is not None,
                "database_distance": direct_route.distance_km if direct_route else None,
                "calculated_distance": round(calculated_distance, 2)
            },
            "route_details": {
                "origin": {
                    "code": origin_airport.iata_code,
                    "name": origin_airport.name,
                    "city": origin_airport.city,
                    "country": origin_airport.country,
                    "coordinates": [origin_airport.latitude, origin_airport.longitude]
                },
                "destination": {
                    "code": destination_airport.iata_code,
                    "name": destination_airport.name,
                    "city": destination_airport.city,
                    "country": destination_airport.country,
                    "coordinates": [destination_airport.latitude, destination_airport.longitude]
                },
                "distance_km": round(actual_distance, 2),
                "flight_time_hours": round(actual_distance / 800, 2)
            },
            "tech_stack_results": {
                "openflights_data": f"✅ Loaded from your SQL database",
                "pytorch_embedding": f"✅ Generated {len(embedding_list)}-dimensional vector",
                "mido_midi": f"✅ Created {note_count} notes, {duration_seconds:.1f}s composition",
                "midi_file_saved": f"✅ {midi_filename}" if midi_saved else "❌ File save failed",
                "duckdb_analytics": "✅ Route logged to analytics",
                "redis_pubsub": f"✅ Published to {subscribers} subscribers"
            },
            "next_steps": [
                "✅ Simple demo successful with your existing database!",
                "🎵 MIDI file created (if file system allows)",
                "📊 Analytics logged to DuckDB",
                "🔌 Redis Pub/Sub message sent",
                "💡 This demo works with your current SQL setup"
            ]
        }
        
    except Exception as e:
        import traceback
        error_traceback = traceback.format_exc()
        logger.error(f"Simple demo error: {e}")
        logger.error(f"Full traceback: {error_traceback}")
        return {
            "demo_type": "simple_demo",
            "status": "error",
            "error": str(e),
            "error_type": type(e).__name__,
            "traceback": error_traceback.split('\n')[-10:],  # Last 10 lines
            "troubleshooting": [
                "❌ Check database connection",
                "❌ Verify airports exist in your SQL tables", 
                "❌ Check file system permissions for MIDI output",
                "💡 Try the debug endpoints first"
            ]
        }


@router.get("/websocket-test-page")
async def websocket_test_page():
    """
    🔌 WebSocket Test Page
    
    Returns HTML page to test WebSocket connections easily
    """
    html_content = '''
<!DOCTYPE html>
<html>
<head>
    <title>Aero Melody WebSocket Test</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .status { padding: 10px; margin: 10px 0; border-radius: 5px; }
        .connected { background: #d4edda; color: #155724; }
        .disconnected { background: #f8d7da; color: #721c24; }
        button { padding: 10px 20px; margin: 5px; }
        #messages { height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px; }
    </style>
</head>
<body>
    <h1>🎵 Aero Melody WebSocket Test</h1>
    
    <div id="status" class="status disconnected">❌ Disconnected</div>
    
    <button onclick="connectWS()">Connect WebSocket</button>
    <button onclick="disconnectWS()">Disconnect</button>
    <button onclick="testAPI()">Test API</button>
    
    <h3>Messages:</h3>
    <div id="messages"></div>
    
    <script>
        let ws = null;
        
        function addMessage(msg) {
            const messages = document.getElementById('messages');
            const div = document.createElement('div');
            div.innerHTML = new Date().toLocaleTimeString() + ': ' + msg;
            messages.appendChild(div);
            messages.scrollTop = messages.scrollHeight;
        }
        
        function updateStatus(connected) {
            const status = document.getElementById('status');
            if (connected) {
                status.textContent = '✅ Connected to Redis WebSocket';
                status.className = 'status connected';
            } else {
                status.textContent = '❌ Disconnected';
                status.className = 'status disconnected';
            }
        }
        
        function connectWS() {
            try {
                ws = new WebSocket('ws://localhost:8000/api/v1/demo/simple-websocket-test');
                
                ws.onopen = function() {
                    updateStatus(true);
                    addMessage('🎉 Connected to WebSocket!');
                    ws.send('Hello from test page!');
                };
                
                ws.onmessage = function(event) {
                    const data = JSON.parse(event.data);
                    addMessage('📨 Received: ' + JSON.stringify(data, null, 2));
                };
                
                ws.onclose = function() {
                    updateStatus(false);
                    addMessage('🔌 WebSocket closed');
                };
                
                ws.onerror = function(error) {
                    addMessage('❌ WebSocket error: ' + error);
                };
                
            } catch (error) {
                addMessage('❌ Connection failed: ' + error);
            }
        }
        
        function disconnectWS() {
            if (ws) {
                ws.close();
                ws = null;
            }
        }
        
        async function testAPI() {
            try {
                addMessage('🧪 Testing API...');
                const response = await fetch('/api/v1/demo/simple-demo?origin=DEL&destination=LHR');
                const data = await response.json();
                addMessage('✅ API Test: ' + data.status + ' - ' + data.route_details?.origin?.name + ' → ' + data.route_details?.destination?.name);
            } catch (error) {
                addMessage('❌ API Test failed: ' + error);
            }
        }
    </script>
</body>
</html>
    '''
    
    from fastapi.responses import HTMLResponse
    return HTMLResponse(content=html_content)